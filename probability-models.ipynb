{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chains Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapman-Kolmogorov Equations \n",
    "\n",
    "$P_{ij}^{n+m}=\\sum_{k=0}^{\\infty}P_{ik}^{n}P_{kj}^{m}$. The proof is just via conditional probability.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification of States\n",
    "\n",
    "- State $j$ is said to be **accessible** from state $i$ if $P_{ij}^n > 0$ for some $n\\geq 0$. Two states $i$ and $j$ that are accessible to each other are said to **communicate**. Communication is a class property. The Markov chain is said to be **irreducible** if there is only one class, that is, if all states communicate with each other.\n",
    "\n",
    "- For any state $i$ we let $f_i$ denote the probability that, starting in state $i$, the\n",
    "process will ever reenter state $i$. State $i$ is said to be **recurrent** if $f_i = 1$ and **transient** if $f_i < 1$. \n",
    "\n",
    "- If state $i$ is recurrent then, starting in state $i$, the process will reenter state $i$ again and again and again—in fact, infinitely often. State $i$ is recurrent if and only if $\\sum_{n=0}^{\\infty}P_{ii}^n = \\infty$. If state $i$ is recurrent, and state $i$ communicates with state $j$, then state $j$ is recurrent. Since not all states in a finite Markov chain can be transient, all states of a finite irreducible Markov chain are recurrent.\n",
    "\n",
    "    - Interestingly enough, whereas the symmetric random walks in one and two dimensions are both recurrent, all higher-dimensional symmetric random walks turn out to be transient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limiting Probabilities\n",
    "\n",
    "- State $i$ is said to have **period $d$** if $P^n_{ii} = 0$ whenever $n$ is not divisible by $d$, and $d$ is the largest integer with this property. A state with period 1 is said to be **aperiodic**. It can be shown that periodicity is a class property. That is, if state $i$ has period $d$, and states $i$ and $j$ communicate, then state $j$ also has period $d$.\n",
    "\n",
    "- If state $i$ is recurrent, then it is said to be **positive recurrent** if, starting in $i$, the expected time until the process returns to state $i$ is finite. It can be shown that positive recurrence is a class property. While there exist recurrent states that are not positive recurrent, it can be shown that in a finite-state Markov chain all recurrent states are positive recurrent. Positive recurrent, aperiodic states are called **ergodic**.\n",
    "\n",
    "- For an irreducible ergodic Markov chain $\\lim_{n\\rightarrow\\infty} P_{ij}^n$ exists and is independent of $i$. Furthermore, letting \n",
    "$$\\pi_j = \\lim_{n\\rightarrow\\infty} P_{ij}^n,\\;\\; j\\geq 0,$$\n",
    "then $\\pi_j$ is the unique nonnegative solution of \n",
    "\\begin{align}\n",
    "\\pi_j &= \\sum_{i=0}^{\\infty}\\pi_iP_{ij},\\;\\; j\\geq 0,\\\\\n",
    "\\sum_{i=0}^{\\infty}\\pi_j &= 1.\n",
    "\\end{align}\n",
    "    - Several more comments on the above:\n",
    "        - The long run proportions $\\pi_j, j\\geq 0$, are often called **stationary probabilities**. The reason being that if the initial state is chosen according to the probabilities $\\pi_j, j\\geq 0$, then the probability of being in state $j$ at any time $n$ is also equal to $\\pi_j$. Also, it can be shown that $\\pi_j$, the limiting probability that the process will be in\n",
    "state $j$ at time $n$, also equals the long-run proportion of time that the process will be in state $j$.\n",
    "        - For state $j$, define $m_{jj}$ to be the expected number of transitions until a Markov chain, starting in state $j$, returns to that state. Then $\\pi_j = \\frac{1}{m_{jj}}$. This is a result of the strong law for renewal process.\n",
    "        - If the Markov chain is irreducible, then there will be a solution to\n",
    "        \\begin{align}\n",
    "        \\pi_j &= \\sum_{i=0}^{\\infty}\\pi_iP_{ij},\\;\\; j\\geq 0,\\\\\n",
    "        \\sum_{i=0}^{\\infty}\\pi_j &= 1.\n",
    "        \\end{align}\n",
    "        if and only if the Markov chain is positive recurrent. If a solution exists then it will be unique, and $\\pi_j$ will equal the long run proportion of time that the Markov chain is in state $j$. If the chain is aperiodic, then $\\pi_j$ is also the limiting probability that the chain is in state $j$.\n",
    "        \n",
    "- Let $\\{X_n, n\\geq 1\\}$ be an irreducible Markov chain with stationary probabilities $\\pi_j, j \\geq 0$, and let $r$ be a bounded function on the state space. Then, with probability 1, \n",
    "\\begin{align}\n",
    "\\lim_{N\\rightarrow\\infty}\\frac{\\sum_{n=1}^N r(X_n)}{N} = \\sum_{j=0}^{\\infty} r(j)\\pi_j\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Reversible Markov Chains\n",
    "\n",
    "- The reverse process of a stationary ergodic Markov chain is itself a Markov chain, because conditioning on the present, the past is independent of the future. A Markov chain is said to be **time reversible**, if \n",
    "\\begin{align}\n",
    "\\pi_iP_{ij} = \\pi_jP_{ji}.\n",
    "\\end{align}\n",
    "If we can find nonnegative numbers, summing to one, that satisfy the equation above, then it follows that the Markov chain is time reversible and the numbers represent the limiting probabilities. But note that it is a sufficient condition: not all ergodic Markov chain is time reversible.\n",
    "\n",
    "- An ergodic Markov chain for which $P_{ij} = 0$ whenever $P_{ji} = 0$ is time reversible if and only if starting in state $i$, any path back to $i$ has the same probability as the reversed path. That is, if\n",
    "\\begin{align}\n",
    "P_{i, i_1}\\dots P_{i_k, i} = P_{i, i_k}\\dots P_{i_1, i},\n",
    "\\end{align}\n",
    "for all states $i, \\dots, i_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Poisson Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Equivalent Definition of the Poisson Process\n",
    "\n",
    "The counting process ${N(t),t\\geq 0}$ is said to be a **Poisson process** having rate $\\lambda$, $\\lambda > 0$, if\n",
    "(i) $N(0) = 0$\n",
    "(ii) The process has independent increments\n",
    "(iii) The number of events in any interval of length $t$ is Poisson distributed with mean $\\lambda t$. That is, for all $s, t \\geq 0$, $P(N(t+s) - N(s)=n)=e^{-\\lambda t}\\frac{(\\lambda t)^n}{n!}$.\n",
    "\n",
    "(ii) and (iii) above can be equivalently replaced by\n",
    "\n",
    "(ii) The process has independent and stationary increments\n",
    "(iii) $P(N(h)=1)=\\lambda h + o(h)$.\n",
    "(iv) $P(N(h)\\geq 2)=o(h)$.\n",
    "\n",
    "The equivalence can be proved by solving for moment-generating function of $N(t)$. Note that the result that $N(t)$ has a Poisson distribution is a consequence of the Poisson approximation to the binomial distribution.\n",
    "\n",
    "By the way, when $\\lambda = \\lambda(t)$, it becomes a non-homogenous Poisson process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrival Time of Poisson Process\n",
    "\n",
    "- Unconditional density of $S_n$: $f_{S_n}(t) = \\lambda e^{-\\lambda t}\\frac{(\\lambda t)^{n-1}}{(n-1)!}$.  Can be proving by noting the first $(n-1)$ events are by time $t$.\n",
    "\n",
    "- Conditional distribution\n",
    "    - Given that $N(t) = n$, the $n$ arrival times $S_1,...,S_n$ have the same distribution as the order statistics corresponding to $n$ independent random variables uniformly distributed on the interval $(0,t)$. In other words, under the condition that $n$ events have occurred in $(0,t)$, the times $S_1,...,S_n$ at which events occur, considered as unordered random variables, are distributed independently and uniformly in the interval $(0,t)$.\n",
    "    - Given that $S_n = t$, the set $S_1,...,S_{n-1}$ has the distribution of a set of $n − 1$ independent uniform $(0, t)$ random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summing and Thinning Properties of Poisson Process\n",
    "\n",
    "Need the sub processes to be independent - has implications in CTMC; see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compound Poisson Process\n",
    "\n",
    "A stochastic process ${X(t),t\\geq 0}$ is said to be a compound Poisson process if it\n",
    "can be represented as \n",
    "\\begin{align}\n",
    "X(t) = \\sum_{i=1}^{N(t)} Y_i, \\;\\; t\\geq 0\n",
    "\\end{align}\n",
    "where ${N(t),t\\geq 0}$ is a Poisson process, and $Y_i,i\\geq 1$ is a family of independent and identically distributed random variables that is also independent of $N(t)$.\n",
    "\n",
    "Note that the expectation and variance of compound Poisson may not be what you expect without actually doing the calculation:\n",
    "\\begin{align}\n",
    "E[X(t)] &= \\lambda t E[Y]\\\\\n",
    "Var[X(t)] &= \\lambda t E[Y^2]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continous Time Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CTMC and DTMC\n",
    "\n",
    "The Markov property of CTMC implies that the waiting time at each state must be memoryless, and thus be exponential. In other words, a continuous-time Markov chain is a stochastic process that moves from state to state in accordance with a (discrete-time) Markov chain, but is such that the amount of time it spends in each state, before proceeding to the next state, is exponentially distributed. In addition, the amount of time the process spends in state $i$, and the next state visited, must be independent random variables.\n",
    "\n",
    "One can picture the process is waiting for one exponential clock and then flip a coin to decide transition to which state, or waiting for a bunch of exponential clock and decide which next state to transition to if that clock goes off first; this is relating to the thinning and summing properties of exponentials. Formally, let $q_{ij}$ be the instantaneous transtion rates between $i$ and $j$, and $v_i$ the transition rate out of state $i$, then the relationship between the instanteneous transition rates of the CTMC and those of the skeleton DTMC is\n",
    "\\begin{align}\n",
    "q_{ij} = v_i P_{ij}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kolmogorov's Equations\n",
    "\n",
    "Let $P_{ij}(t) = P(X(t+s)=j|X(s)=i)$ be the transition probability of the CTMC. \n",
    "\n",
    "Then the ***Kolmogorov's Backward Equations*** is\n",
    "\n",
    "\\begin{align}\n",
    "P_{ij}'(t) = \\sum_{k\\neq i}q_{ik}P_{kj}(t) - v_i P_{ij}(t).\n",
    "\\end{align}\n",
    "\n",
    "And ***Kolmogorov's Forward Equations*** are\n",
    "\n",
    "\\begin{align}\n",
    "P_{ij}'(t) = \\sum_{k\\neq j}P_{ik}(t)q_{kj} - P_{ij}(t)v_j.\n",
    "\\end{align}\n",
    "\n",
    "The intuition about these equations is to think about $P_{ij}(t+h)$. To transit from $i$ to $j$ in $t+h$, it can either transit to a state $k\\neq i$ in $h$ and then $k$ to $j$ in $[h, t+h]$, or it can stay in $i$ for $h$ and simply transit from $i$ to $j$ in $[h, t+h]$. Along this line you get the backward equations, since you are looking backward for a period of $h$ before you start a period of $t$. Similarly you get the forward equations when the period of $t$ is before the short period of $h$.\n",
    "\n",
    "These equations can be used to solve for the transition probabilities $P_{ij}(t)$. Let\n",
    "\\begin{align}\n",
    "r_{ij}=\\begin{cases}\n",
    "q_{ij},\\;\\;\\text{if}\\;i\\neq j\\\\\n",
    "-v_i,\\;\\;\\text{if}\\;i=j\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Then the Kolmogorov equations can be rewritten as follows.\n",
    "\\begin{align}\n",
    "P_{ij}'(t) &= \\sum_{k\\neq i}r_{ik}P_{kj}(t)\\;\\;\\text{(backward)}\\\\\n",
    "P_{ij}'(t) &= \\sum_{k\\neq j}P_{ik}(t)r_{kj}\\;\\;\\text{(forward)},\n",
    "\\end{align}\n",
    "or in matrix notation\n",
    "\\begin{align}\n",
    "\\mathbf{P}'(t) &= \\mathbf{R}\\mathbf{P}(t)\\;\\;\\text{(backward)}\\\\\n",
    "\\mathbf{P}(t) &= \\mathbf{P}(t)\\mathbf{R}\\;\\;\\text{(forward)}.\n",
    "\\end{align}\n",
    "Thus \n",
    "\\begin{align}\n",
    "\\mathbf{P}(t) = \\sum_{n=0}^{\\infty}R^n\\frac{t^n}{n!},\n",
    "\\end{align}\n",
    "since $\\mathbf{P}(0)=\\mathbf{I}$. To numerically calculate $\\sum_{n=0}^{\\infty}R^n\\frac{t^n}{n!}$, we make use of the following identity (which a matrix equivalence of the exponential function)\n",
    "\\begin{align}\n",
    "\\sum_{n=0}^{\\infty}R^n\\frac{t^n}{n!} = \\lim_{n\\rightarrow\\infty}\\left(\\mathbf{I}+\\mathbf{R}\\frac{t}{n}\\right)^n.\n",
    "\\end{align}\n",
    "The further trick is to choose $n=2^k$ so that you only need to perform matrix multiplication $k$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limiting Probabilities\n",
    "\n",
    "Similar to DTMC, limiting probabilities of CTMC exists when it is irreducible and the Markov chain is positive recurrent. This is a sufficient condition for renewal type of theory to take effect. A CTMC is called **ergodic** when the limiting probabilities exist.\n",
    "\n",
    "When limiting probabilities exist, one can solve for them by taking limits in the Kolmogorov equations, i.e.\n",
    "\\begin{align}\n",
    "0=\\sum_{k\\neq j}q_{kj}P_k - v_j P_j.\n",
    "\\end{align}\n",
    "The above has an intuitive meaning, which is when the CTMC is at its limit and hence in stationarity, the transition from outside of state $j$ should equal to the flow out of state $j$. The above and the normalizing condition that all probabilities should sum to $1$:\n",
    "\\begin{align}\n",
    "\\sum_j P_j = 1,\n",
    "\\end{align}\n",
    "give the limiting probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Reversibility\n",
    "\n",
    "The time reversibility of a CTMC is similar to that of the DTMC, in that discrete transition probabilities are replaced by transition rates:\n",
    "\\begin{align}\n",
    "\\pi_iq_{ij} = \\pi_jq_{ji}.\n",
    "\\end{align}\n",
    "Note that here $\\pi_i$ should be interpreted as the long-term proportion of time spent in state $i$, which coincide with the limiting probabilities of the CTMC. The above has the similar intuitive interpretation, which is that the rate at which the process goes directly from state $i$ to state $j$ is equal to the rate at which it goes directly from $j$ to $i$.\n",
    "\n",
    "An ergodic birth and death process is time reversible. In particular, for an $M/M/s$ no abandon queue with arrival rate $\\lambda$ and departure rate $\\mu$, as long as $\\lambda < s\\mu$, it is a time-reversible CTMC. After this queue operates for a long time and thus stationary, the departure process of the queue is a Poisson process of rate $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renewal Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renewal Process \n",
    "\n",
    "If the sequence of nonnegative random variables $\\{X_1, X_2, \\dots\\}$ is independent and identically distributed, then the counting process $\\{N(t), t\\geq 0\\}$ is said to be a **renewal process**. \n",
    "\n",
    "The number of renewals by time $t$ is greater than or equal to $n$ if and only if the $n$-th renewal occurs before or at time $t$. That is, \n",
    "\\begin{align}\n",
    "N(t) \\geq n \\iff S_n \\leq t.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Useful Identities\n",
    "\n",
    "The mean-value or the **renewal function** is \n",
    "\\begin{align}\n",
    "m(t) = E(N(t)).\n",
    "\\end{align}\n",
    "Further denote the CDF, density and mean of $X$ as $F$, $f$ and $\\mu$. Then $m(t)$ uniquely determines the interarrival distribution, and it follows that the Poisson process is the only renewal process having a linear mean-value function.\n",
    "\n",
    "The **renewal equation** is the follows.\n",
    "\\begin{align}\n",
    "m(t) = F(t) + \\int_0^t m(t-x)f(x)dx,\n",
    "\\end{align}\n",
    "which can be proved by conditioning on the first arrival.\n",
    "\n",
    "If we let $g(t) = E[S_{N(t)+1}]$, then similarly by conditioning on the first arrival, we have\n",
    "\\begin{align}\n",
    "g(t) = \\mu + \\int_0^t g(t-x)f(x)dx\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limiting Theorems\n",
    "\n",
    "- With probability 1, $\\frac{N(t)}{t} \\rightarrow \\frac{1}{\\mu}$, as $t\\rightarrow\\infty$. The number $\\frac{1}{\\mu}$ is called the **rate** of the renewal process.\n",
    "- **Elementary Renewal Theorem** $\\frac{m(t)}{t} \\rightarrow \\frac{1}{\\mu}$, as $t\\rightarrow\\infty$.\n",
    "\n",
    "Both of these have implications in DTMC and CTMC above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renewal Reward Process\n",
    "\n",
    "A large number of probability models are special cases of the following renewal reward process. Consider a renewal process $N(t)$, having interarrival times $X_n$, and suppose that each time a renewal occurs we receive a reward. We denote by $R_n$, the reward earned at the time of the $n$-th renewal. We shall assume that the $R_n$, are independent and identically distributed. However, we do allow for the possibility that $R_n$ may (and usually will) depend on $X_n$, the length of the $n$-th renewal interval. If we let\n",
    "\\begin{align}\n",
    "R(t) = \\sum_{n=1}^{N(t)} R_n,\n",
    "\\end{align}\n",
    "then $R(t)$ represents the total reward earned by time $t$. Let\n",
    "\\begin{align}\n",
    "E(R) = E(R_n),\\;\\;E(X) = E(X_n).\n",
    "\\end{align}\n",
    "\n",
    "If $E(R)<\\infty$ and $E(X)<\\infty$, then\n",
    "- with probability 1, $\\lim_{t\\rightarrow\\infty}\\frac{R(t)}{t}=\\frac{E(R)}{E(X)}$\n",
    "- $\\lim_{t\\rightarrow\\infty}\\frac{E[R(t)]}{t}=\\frac{E(R)}{E(X)}$.\n",
    "\n",
    "One application of the above is to solve for the average age/excess of a renewal process, i.e. $\\lim_{s\\rightarrow\\infty}\\frac{\\int_{0}^sA(t)dt}{s}$ and $\\lim_{s\\rightarrow\\infty}\\frac{\\int_{0}^sY(t)dt}{s}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Queueing Model for ALM for Banking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model the arrival and departure of deposit as a queuing system. \n",
    "- Discretize the dollar amount and assume aggregate arrivals and departures are in unit of certain amount, e.g. in 1K or 10K.\n",
    "- The process can then be characterized as an $M/M/\\infty$ queue.\n",
    "    - Treat arrivals and departures as 'events', and just estimate this event rate using historical data. \n",
    "    - Then it suffices to calibrate the embedded DTMC, whose transition probability can be again estimated from historical data (here you can see why we need to discretize)\n",
    "    - To deal with seasonality in deposits, maybe we can generalize to $M_t/M_t/\\infty$ queue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [ < Introduction to Probability Models >, 9th Edition ](https://www.evernote.com/shard/s191/nl/21353936/861cc77d-0791-45d2-969a-ec51049bab43?title=Ross%20Intro%20to%20Probability%20Models.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
